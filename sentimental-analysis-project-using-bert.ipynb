{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T04:55:06.725388Z","iopub.execute_input":"2025-05-12T04:55:06.725720Z","iopub.status.idle":"2025-05-12T04:55:08.953064Z","shell.execute_reply.started":"2025-05-12T04:55:06.725692Z","shell.execute_reply":"2025-05-12T04:55:08.952103Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"**In this project I am gonna be learning to use BERT model to do sentiment analysis and after that I am be usng web scraping to test some reviews from a website.**\n","metadata":{}},{"cell_type":"code","source":"!pip install transformers requests beautifulsoup4 streamlit pyngrok","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T04:55:08.954759Z","iopub.execute_input":"2025-05-12T04:55:08.955305Z","iopub.status.idle":"2025-05-12T04:55:16.255456Z","shell.execute_reply.started":"2025-05-12T04:55:08.955271Z","shell.execute_reply":"2025-05-12T04:55:16.254087Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\nCollecting streamlit\n  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\nCollecting pyngrok\n  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\nRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\nRequirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.3)\nRequirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\nRequirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (19.0.1)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\nRequirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\nRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\nRequirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.26.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\nDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 pyngrok-7.2.8 streamlit-1.45.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\ntokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\nmodel = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\ntokens = tokenizer.encode('bert is absolutely great', return_tensors='pt')\nresult = model(tokens)\nresult.logits\nint(torch.argmax(result.logits))+1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T04:55:16.257018Z","iopub.execute_input":"2025-05-12T04:55:16.257483Z","iopub.status.idle":"2025-05-12T04:55:56.907764Z","shell.execute_reply.started":"2025-05-12T04:55:16.257437Z","shell.execute_reply":"2025-05-12T04:55:56.906562Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b91d0b0f664a0ab9e5e0982b517c32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b786c934ff0423ea6802b8681c0eb31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efa27264996d4a38ab62387c6e3210d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f3ab514b646428bb0ec3173753260ee"}},"metadata":{}},{"name":"stderr","text":"2025-05-12 04:55:39.612255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747025739.860919      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747025739.935367      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/669M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cbe6a6c108f46fea7f7471603baf2f9"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"This 4 means positive, see the chart - \n\n1 star = Very Negative\n\n2 stars = Negative\n\n3 stars = Neutral\n\n4 stars = Positive\n\n5 stars = Very Positive","metadata":{}},{"cell_type":"markdown","source":"Now what we are going to do, we are going to scrape the data from a website called Yelp, which is basically a website for reviews. And we are going to scrape the data and we are going to know that whether the model is going to work on the given dataset or not from the website, so that we can make a website around this project that the common user can also use.","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport re\nr = requests.get('https://www.yelp.com/biz/social-brew-cafe-pyrmont')\nsoup = BeautifulSoup(r.text, 'html.parser')\nregex = re.compile('.*comment.*')\nresults = soup.find_all('p', {'class':regex})\nreviews = [result.text for result in results]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T04:55:56.909482Z","iopub.execute_input":"2025-05-12T04:55:56.910093Z","iopub.status.idle":"2025-05-12T04:56:00.446371Z","shell.execute_reply.started":"2025-05-12T04:55:56.910065Z","shell.execute_reply":"2025-05-12T04:56:00.445447Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Now I am gonna rewrite the whole code for doing the sentiment analysis on each review to know whether the fine tuning is feasible or not\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\n\n# Load the pre-trained sentiment analysis model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\nmodel = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\n# Function to get sentiment from the model\ndef get_sentiment(text):\n    tokens = tokenizer.encode(text, return_tensors='pt')\n    result = model(tokens)\n    sentiment_score = int(torch.argmax(result.logits)) + 1  # Sentiment range from 1 to 5\n    return sentiment_score\n\n# Scrape reviews from Yelp\nurl = 'https://www.yelp.com/biz/social-brew-cafe-pyrmont'  # Replace with your desired Yelp URL\nr = requests.get(url)\nsoup = BeautifulSoup(r.text, 'html.parser')\n\n# Use a regex to find all review-related elements\nregex = re.compile('.*comment.*')\nresults = soup.find_all('p', {'class': regex})\n\n# Extract reviews text\nreviews = [result.text for result in results]\n\n# Apply sentiment analysis for each review\nreview_sentiments = []\nfor review in reviews:\n    sentiment = get_sentiment(review)\n    review_sentiments.append((review, sentiment))\n\n# Print out reviews with sentiment scores\nfor review, sentiment in review_sentiments:\n    print(f\"Review: {review}\\nSentiment Score: {sentiment}\\n{'-'*50}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T04:56:00.447298Z","iopub.execute_input":"2025-05-12T04:56:00.447912Z","iopub.status.idle":"2025-05-12T04:56:05.849851Z","shell.execute_reply.started":"2025-05-12T04:56:00.447887Z","shell.execute_reply":"2025-05-12T04:56:05.848828Z"}},"outputs":[{"name":"stdout","text":"Review: Very cute coffee shop and restaurant. They have a lovely outdoor seating area and several tables inside.  It was fairly busy on a Tuesday morning but we were to grab the last open table. The server was so enjoyable, she chatted and joked with us and provided fast service with our ordering, drinks and meals. The food was very good. We ordered a wide variety and every meal was good to delicious. The sweet potato fries on the Chicken Burger plate were absolutely delicious, some of the best I've ever had. I definitely enjoyed this cafe, the outdoor seating, the service and the food!!\nSentiment Score: 5\n--------------------------------------------------\nReview: Amazing ambience. Coffee was the best we've had in Sydney. The service and food also great. As must stop for breakfast.\nSentiment Score: 5\n--------------------------------------------------\nReview: Six of us met here for breakfast before our walk to Manly. We were enjoying visiting with each other so much that I apologize for not taking any photos. We all enjoyed our food, as well as our coffee and tea drinks.We were greeted immediately by a friendly server asking if we would like to sit inside or out. We said we would like inside, but weren't exactly sure how many were joining us yet- at least 4. We were told this was no problem, the more the merrier. A few minutes later when 4 more joined our party and we explained to the server we had 6, he just quickly switched our table. I really enjoyed my serenity tea, just what I needed after a long flight in from Sfo that morning. Everyone else were more interested in the lattes for expresso drinks. All said they were hot and delicious. 2 of us ordered the avo on toast. So yummy with the beetroot... I will start adding this to mine now at home, and have fond memories for my trip to Sydney. 2 friends ordered the salmon Benedict- saying it was delicious, and their go to every time they come here. 2 friends had a breakfast sandwich- I'm not sure of the name. It did look delicious. Adorable cafe, friendly staff, clean restroomsVery popular with the locals. I plan to come back the next time I'm in Sydney\nSentiment Score: 4\n--------------------------------------------------\nReview: We came for brunch and they ran out of seven separate menu items. We tried ordering multiple times and each time were let down with them not having what we wanted. It's understandable to not have certain things, but to have half of your menu not available is a bit ridiculous. When we finally were able to get something it was good, but we had to wait around 10-15 minutes after ordering to be told that they were out of something. Disappointing because of high expectations.\nSentiment Score: 2\n--------------------------------------------------\nReview: Ricotta hot cakes! These were so yummy. I ate them pretty fast and didn't share with anyone because they were that good ;). I ordered a green smoothie to balance it all out. Smoothie was a nice way to end my brekkie at this restaurant. Others with me ordered the salmon Benedict and the smoked salmon flatbread. They were all delicious and all plates were empty. Cheers!\nSentiment Score: 5\n--------------------------------------------------\nReview: Great food amazing coffee and tea. Short walk from the harbor. Staff was very friendly\nSentiment Score: 5\n--------------------------------------------------\nReview: We came for brunch twice in our week-long visit to Sydney. Everything on the menu not only sounds delicious, but is really tasty. It really gave us a sour taste of how bad breaky is in America with what's so readily available in Sydney!  Both days we went were Saturdays and there was a bit of a wait to be seated, the cafe is extremely busy for both dine-in and take-away. Service is fairly quick and servers are all friendly. The location is in Surrey Hills a couple blocks away from the bustling touristy Darling Harbor.The green smoothie is very tasty and refreshing. We tried the smoked salmon salad, the soft shell crab tacos, ricotta hotcakes, and the breaky sandwich. All were delicious, well seasoned, and a solid amount of food for the price. A definite recommend for anyone's trip into Sydney!\nSentiment Score: 5\n--------------------------------------------------\nReview: Great place with delicious food and friendly staff. It is small but has outdoor seating and a relaxed ambiance. Perfect place to enjoy a cup of coffee. I am visiting Sydney for the first time but this place seems like is a local favorite.\nSentiment Score: 5\n--------------------------------------------------\nReview: The food was delicious. The ricotta pancakes were light and tasty.  The cream br√ªl√©e French toast was a fruit lovers delight. There was fresh strawberries, blueberries, passion fruit and custard. No syrup required. And crispy kale as a side ordered with eggs. Worth the walk over the Pyrmont bridge.\nSentiment Score: 4\n--------------------------------------------------\nReview: Great service, lovely location, and really amazing food. Words don't do justice. We had the mushroom parm bruschetta and the loaded double double. Both were so tasty. Also love the Aussie black tea and a flat white. Wish I had more mornings in Sydney to eat breakfast there. Highly recommend.\nSentiment Score: 5\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":5},{"cell_type":"raw","source":"reviews","metadata":{}},{"cell_type":"markdown","source":"Making the web app to make the app feasible","metadata":{}},{"cell_type":"markdown","source":"\n\n","metadata":{},"attachments":{}},{"cell_type":"code","source":"import streamlit as st\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nimport os\nimport subprocess\nimport time\nfrom pyngrok import ngrok\n\n# ========== ENVIRONMENT ==========\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# ========== MODEL ==========\ntokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\nmodel = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\ndef get_sentiment_label(score):\n    return {\n        1: \"Very Negative\",\n        2: \"Negative\",\n        3: \"Neutral\",\n        4: \"Positive\",\n        5: \"Very Positive\"\n    }.get(score, \"Unknown\")\n\ndef get_sentiment(text):\n    tokens = tokenizer.encode(text, return_tensors='pt')\n    result = model(tokens)\n    score = int(torch.argmax(result.logits)) + 1\n    label = get_sentiment_label(score)\n    return score, label\n\n# ========== STREAMLIT APP CODE ==========\nwith open(\"app.py\", \"w\") as f:\n    f.write(\"\"\"\nimport streamlit as st\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nimport os\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\ntokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\nmodel = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n\ndef get_sentiment_label(score):\n    return {\n        1: \"Very Negative\",\n        2: \"Negative\",\n        3: \"Neutral\",\n        4: \"Positive\",\n        5: \"Very Positive\"\n    }.get(score, \"Unknown\")\n\ndef get_sentiment(text):\n    tokens = tokenizer.encode(text, return_tensors='pt')\n    result = model(tokens)\n    score = int(torch.argmax(result.logits)) + 1\n    label = get_sentiment_label(score)\n    return score, label\n\nst.title(\"Sentimeter\")\nreview = st.text_area(\"Enter a review:\")\n\nif st.button(\"Find\"):\n    if review:\n        score, label = get_sentiment(review)\n        # Color-based output based on sentiment label\n        if label == \"Very Positive\" or label == \"Positive\":\n            st.markdown(f'<div style=\"background-color: green; padding: 10px; color: white; border-radius: 5px;\">{label}</div>', unsafe_allow_html=True)\n        elif label == \"Negative\" or label == \"Very Negative\":\n            st.markdown(f'<div style=\"background-color: #D22B2B; padding: 10px; color: white; border-radius: 5px;\">{label}</div>', unsafe_allow_html=True)\n        else:\n            st.write(f\"{label}\")  # For Neutral, just plain text\n    else:\n        st.warning(\"Please enter a review.\")\n    \"\"\")\n\n# ========== NGROK SETUP ==========\nngrok.kill()  # kill any previous sessions\nngrok.set_auth_token(\" replace with your real token\")  \n\n# Start the Streamlit app\nprocess = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\ntime.sleep(5)  # wait for streamlit to boot up\n\n# Get public URL from ngrok\npublic_url = ngrok.connect(8501)\nprint(\"üöÄ App running at:\", public_url)\n\n# Keep it alive (manually stop from \"Stop Execution\" button in Kaggle)\nprocess.wait()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T05:50:46.643163Z","iopub.execute_input":"2025-05-12T05:50:46.643493Z"}},"outputs":[{"name":"stdout","text":"\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\n\n  You can now view your Streamlit app in your browser.\n\n  Local URL: http://localhost:8501\n  Network URL: http://172.19.2.2:8501\n  External URL: http://34.141.218.43:8501\n\nüöÄ App running at: NgrokTunnel: \"https://d957-34-141-218-43.ngrok-free.app\" -> \"http://localhost:8501\"\n","output_type":"stream"},{"name":"stderr","text":"2025-05-12 05:51:08.092261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747029068.125784     218 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747029068.135717     218 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-05-12 05:51:12.762 Examining the path of torch.classes raised:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n    if asyncio.get_running_loop().is_running():\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: no running event loop\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n    potential_paths = extract_paths(module)\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n    lambda m: list(m.__path__._path),\n                   ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}